## Problem 1
# Importing libraries
import imageio
import torch

# Inputting an image and converting it to a tensor
img_arr = imageio.imread('/media/green-smoothie-8-1200.jpg')
img_t = torch.from_numpy(img_arr)

# Turning the tensor into floating points 
floatValue = img_t.float()
floatValue /= 255.0

# Calculating the mean on the channel
mC = floatValue.mean()
mC

## Problem 2
# Measured values
t_c = [0.5, 14.0, 15.0, 28.0, 11.0, 8.0, 3.0, -4.0, 6.0, 13.0, 21.0]
t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]
t_c = torch.tensor(t_c)
t_u = torch.tensor(t_u)

def model(t_u, w, b, w2):   # Non-linear Model
  return ((w2 * t_u)**2) + (w * t_u) + b

def loss_fn(t_p, t_c):    # Loss calculation
  squared_diffs = (t_p - t_c)**2
  return squared_diffs.mean()
  
w = torch.ones(())    # initial W is 1
b = torch.zeros(())   # initial b is 0
w2 = torch.ones(())    # initial W2 is 1
t_p = model(t_u, w, b, w2)

loss = loss_fn(t_p, t_c) 

delta = 0.1
loss_rate_of_change_w =  (loss_fn(model(t_u, w + delta, b, w2), t_c) - loss_fn(model(t_u, w - delta, b, w2), t_c)) / (2.0 * delta)
loss_rate_of_change_w2 =  (loss_fn(model(t_u, w2 + delta, b, w2), t_c) - loss_fn(model(t_u, w2 - delta, b, w2), t_c)) / (2.0 * delta)

learning_rate = 1e-2    # means 0.01 as the changing rate for our parameters
w = w - learning_rate * loss_rate_of_change_w
w2 = w2 - learning_rate * loss_rate_of_change_w2

loss_rate_of_change_b = (loss_fn(model(t_u, w, b + delta,w2), t_c) - loss_fn(model(t_u, w, b - delta, w2), t_c)) / (2.0 * delta)
b = b - learning_rate * loss_rate_of_change_b

# Calculate the loss gradient
def dloss_fn(t_p, t_c):
  dsq_diffs = 2 * (t_p - t_c) / t_p.size(0)
  return dsq_diffs

def dmodel_dw2(t_u, w, b, w2):
  return t_u**2

def dmodel_dw(t_u, w, b, w2):
  return t_u

def dmodel_db(t_u, w, b, w2):
  return 1.0

def grad_fn(t_u, t_c, t_p, w, b, w2):
  dloss_dtp = dloss_fn(t_p, t_c)
  dloss_dw2 = dloss_dtp * dmodel_dw(t_u, w, b, w2)
  dloss_dw = dloss_dtp * dmodel_dw(t_u, w, b, w2)
  dloss_db = dloss_dtp * dmodel_db(t_u, w, b, w2) 
  return torch.stack([dloss_dw2.sum(), dloss_dw.sum(), dloss_db.sum()])
  
def training_loop(n_epochs, learning_rate, params, t_u, t_c):
  for epoch in range(1, n_epochs + 1):
    w, b, w2 = params
  
    t_p = model(t_u, w, b, w2)
    loss = loss_fn(t_p, t_c)
    grad = grad_fn(t_u, t_c, t_p, w, b, w2)

    params = params - learning_rate * grad
    if(epoch % 500 == 0):{
        print('Epoch %d, Loss %f' %(epoch, float(loss)))
    }

  return params

t_un = 0.1 * t_u
params = training_loop(5000,1e-5,torch.tensor([1.0, 0.0, 1.0]),t_un, t_c)

%matplotlib inline 
from matplotlib import pyplot as plt
t_p = model(t_un, *params)

fig = plt.figure(dpi = 600)
plt.xlabel("Temperature (oFahrenheit)")
plt.ylabel("Temperature (oCelsius)")
plt.plot(t_u.numpy(), t_p.detach().numpy())
plt.plot(t_u.numpy(), t_c.numpy(), 'o')


## Problem 3
import pandas as pd
csv_file = '/media/Housing.csv'
df = pd.read_csv (csv_file)   
print (df)

# Converting csv file to usable tensor data
import csv
priceS = []
areaS = []
bedroomsS = []
bathroomsS = []
storiesS = []
parkingS = []

price = []
area = []
bedrooms = []
bathrooms = []
stories = []
parking = []

with open(csv_file, 'r') as f:
    reader = csv.DictReader(f)
    for row in reader:
        priceS.append(row.get('price'))
        areaS.append(row.get('area'))
        bedroomsS.append(row.get('bedrooms'))
        bathroomsS.append(row.get('bathrooms'))
        storiesS.append(row.get('stories'))
        parkingS.append(row.get('parking'))

price = [int(numeric_string) for numeric_string in priceS]
area = [int(numeric_string) for numeric_string in areaS]
bedrooms = [int(numeric_string) for numeric_string in bathroomsS]
bathrooms = [int(numeric_string) for numeric_string in bedroomsS]
stories = [int(numeric_string) for numeric_string in storiesS]
parking =  [int(numeric_string) for numeric_string in parkingS]

t_pr = torch.tensor(price) # t_c
t_ar = torch.tensor(area)   # t_u1
t_be = torch.tensor(bedrooms)   # t_u2
t_ba = torch.tensor(bathrooms)  # t_u3
t_st = torch.tensor(stories)    # t_u4
t_pa = torch.tensor(parking)    # t_u5

# Normalization
from math import sqrt
def tensorToNormal(t_y):
  t_y = t_y.float()
  m = t_y.mean()
  v = t_pr.var()
  s = sqrt(v)
  norm = (t_y - m)/ s
  norm /= norm.sum()
  return norm

def norming(t_y):
  t_z = t_y / t_y.sum()
  return t_z

t_pr = norming(t_pr)
t_ar = norming(t_ar)
t_be = norming(t_be)
t_ba = norming(t_ba)
t_st = norming(t_st)
t_pa = norming(t_pa)

def modelN(t_ar, we1,t_be, we2,t_ba, we3,t_st, we4, t_pa, we5, b):   # linear Model
  return  (we1 * t_ar) + (we2 * t_be) + (we3 * t_ba) + (we4 * t_st) + (we5 * t_pa) + bN

def loss_fnN(t_pN, t_pr):    # Loss calculation
  squared_diffs = (t_pN - t_pr)**2
  return squared_diffs.mean()
  
  we1 = torch.ones(())    # initial W1is 1
we2 = torch.ones(())    # initial W2 is 1
we3 = torch.ones(())    # initial W3 is 1
we4 = torch.ones(())    # initial W4 is 1
we5 = torch.ones(())    # initial W5 is 1
bN = torch.zeros(())   # initial b is 0
t_pN =  modelN(t_ar, we1,t_be, we2,t_ba, we3,t_st, we4, t_pa, we5, bN)

# weighted calculations
delta = 0.1
loss_rate_of_change_we1 =  (loss_fnN(modelN(t_ar, we1 + delta, t_be, we2,t_ba, we3,t_st, we4, t_pa, we5, b), t_ar) - loss_fnN(modelN(t_ar, we1 - delta, t_be, we2,t_ba, we3,t_st, we4, t_pa, we5, b), t_ar)) / (2.0 * delta)
loss_rate_of_change_we2 =  (loss_fnN(modelN(t_ar, we1, t_be, we2 + delta, t_ba, we3,t_st, we4, t_pa, we5, b), t_be) - loss_fnN(modelN(t_ar, we1, t_be, we2 - delta,t_ba, we3,t_st, we4, t_pa, we5, b), t_be)) / (2.0 * delta)
loss_rate_of_change_we3 =  (loss_fnN(modelN(t_ar, we1, t_be, we2,t_ba, we3 + delta,t_st, we4, t_pa, we5, b), t_ba) - loss_fnN(modelN(t_ar, we1, t_be, we2,t_ba, we3 - delta,t_st, we4, t_pa, we5, b), t_ba)) / (2.0 * delta)
loss_rate_of_change_we4 =  (loss_fnN(modelN(t_ar, we1, t_be, we2,t_ba, we3,t_st, we4 + delta, t_pa, we5, b), t_st) - loss_fnN(modelN(t_ar, we1, t_be, we2,t_ba, we3,t_st, we4 - delta, t_pa, we5, b), t_st)) / (2.0 * delta)
loss_rate_of_change_we5 =  (loss_fnN(modelN(t_ar, we1, t_be, we2,t_ba, we3,t_st, we4, t_pa, we5 + delta, b), t_pa) - loss_fnN(modelN(t_ar, we1, t_be, we2,t_ba, we3,t_st, we4, t_pa, we5 - delta, b), t_pa)) / (2.0 * delta)

learning_rateN = 1e-2    # means 0.01 as the changing rate for our parameters
we1 = we1 - learning_rateN * loss_rate_of_change_we1
we2 = we2 - learning_rateN * loss_rate_of_change_we2
we3 = we3 - learning_rateN * loss_rate_of_change_we3
we4 = we4 - learning_rateN * loss_rate_of_change_we4
we5 = we5 - learning_rateN * loss_rate_of_change_we5

loss_rate_of_change_b1 = (loss_fnN(modelN(t_ar, we1, t_be,we2, t_ba, we3, t_st, we4, t_pa, we5, b + delta), t_ar) - loss_fnN(modelN(t_ar, we1, t_be,we2, t_ba, we3, t_st, we4, t_pa, we5, b - delta), t_ar)) / (2.0 * delta)
loss_rate_of_change_b2 = (loss_fnN(modelN(t_ar, we1, t_be,we2, t_ba, we3, t_st, we4, t_pa, we5, b + delta), t_be) - loss_fnN(modelN(t_ar, we1, t_be,we2, t_ba, we3, t_st, we4, t_pa, we5, b - delta), t_be)) / (2.0 * delta)
loss_rate_of_change_b3 = (loss_fnN(modelN(t_ar, we1, t_be,we2, t_ba, we3, t_st, we4, t_pa, we5, b + delta), t_ba) - loss_fnN(modelN(t_ar, we1, t_be,we2, t_ba, we3, t_st, we4, t_pa, we5, b - delta), t_ba)) / (2.0 * delta)
loss_rate_of_change_b4 = (loss_fnN(modelN(t_ar, we1, t_be,we2, t_ba, we3, t_st, we4, t_pa, we5, b + delta), t_st) - loss_fnN(modelN(t_ar, we1, t_be,we2, t_ba, we3, t_st, we4, t_pa, we5, b - delta), t_st)) / (2.0 * delta)
loss_rate_of_change_b5 = (loss_fnN(modelN(t_ar, we1, t_be,we2, t_ba, we3, t_st, we4, t_pa, we5, b + delta), t_pa) - loss_fnN(modelN(t_ar, we1, t_be,we2, t_ba, we3, t_st, we4, t_pa, we5, b - delta), t_pa)) / (2.0 * delta)

bN = bN - (learning_rate * loss_rate_of_change_b1 ) - (learning_rate * loss_rate_of_change_b2 ) - (learning_rate * loss_rate_of_change_b3 ) - (learning_rate * loss_rate_of_change_b4 ) - (learning_rate * loss_rate_of_change_b5 )

# Calculate the loss gradient
def dloss_fnN(t_pN, t_pr):
  dsq_diffs = 2 * (t_pN - t_pr) / t_pN.size(0)
  return dsq_diffs

def dmodel_dwN(t_x):
  return t_x

def dmodel_dbN(t_x):
  return 1.0

def grad_fnN(t_ar,t_be, t_ba,t_st, t_pa, bN):
  dloss_dtpN = dloss_fnN(t_pN, t_pr)
  dloss_dw1 = dloss_fnN(t_pN, t_pr) * dmodel_dwN(t_ar)
  dloss_dw2 = dloss_fnN(t_pN, t_pr) * dmodel_dwN(t_be)
  dloss_dw3 = dloss_fnN(t_pN, t_pr) * dmodel_dwN(t_ba)
  dloss_dw4 = dloss_fnN(t_pN, t_pr) * dmodel_dwN(t_st)
  dloss_dw5 = dloss_fnN(t_pN, t_pr) * dmodel_dwN(t_pa)
  
  dloss_dbN = dloss_dtpN * dmodel_dbN(t_pN) 
  return torch.stack([dloss_dw1.sum(), dloss_dw2.sum(), dloss_dw3.sum(),dloss_dw4.sum(), dloss_dw5.sum(), dloss_dbN.sum()])
  
  # Creating training loop
def training_loopN(n_epochs, LRN, paramsN, t_in, t_pr):
  for epoch in range(1, n_epochs + 1):
    we1, we2, we3, we4, we5, bN = paramsN
  
    t_pN = modelN(t_ar, we1,t_be, we2,t_ba, we3,t_st, we4, t_pa, we5, bN)
    lossN = loss_fnN(t_pN, t_pr)
    gradN = grad_fnN(t_ar,t_be, t_ba,t_st, t_pa, bN)

    paramsN = paramsN - LRN * gradN
    if(epoch % 500 == 0):{
        print('Epoch %d, Loss %f' %(epoch, float(lossN)))
    }

  return paramsN
  
  # instantiating training loop
t_uN = t_pr
t_in = 0.1 * t_uN
params2 = training_loopN(5000,1e-3,torch.tensor([1.0, 1.0, 1.0, 1.0, 1.0, 0.0]),t_in, t_pr)
params2

# plotting results
%matplotlib inline 
from matplotlib import pyplot as plt
t_pN = modelN(t_ar, we1,t_be, we2,t_ba, we3,t_st, we4, t_pa, we5, bN)


fig = plt.figure(dpi = 100)
plt.xlabel("Trained Price")
plt.ylabel("Predicted Price")
plt.plot(t_pr.numpy(), t_pN.detach().numpy())
plt.plot(t_pr.numpy(), t_pr.numpy(), 'o')

